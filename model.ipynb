{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "server = \"192.168.2.68\"\n",
    "port = \"27018\"\n",
    "IOTS_READING = [\"BuildingLeftSide\", \"iots_reading_left_side\"]\n",
    "client = MongoClient(server + ':' + port)\n",
    "\n",
    "now = datetime.now()\n",
    "start = now - timedelta(days=6, hours=now.hour, minutes=now.minute)\n",
    "end = start + timedelta(days=1)\n",
    "\n",
    "historic = list(client[IOTS_READING[0]][IOTS_READING[1]].find({'datetime': {'$gt': start, '$lt': end}}))\n",
    "client.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T16:49:02.045237656Z",
     "start_time": "2023-12-18T16:48:50.007928204Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "forecast = pd.DataFrame(historic)\n",
    "total = forecast.drop([\"_id\"], axis=1)\n",
    "\n",
    "total = total.dropna()\n",
    "\n",
    "total = total.values.tolist()\n",
    "total_power = []\n",
    "\n",
    "for row in total:\n",
    "    iots = row[0]\n",
    "    date = row[1]\n",
    "    consumption = 0\n",
    "    for iot in iots:\n",
    "        for value in iot['values']:\n",
    "            if 'values' in value:\n",
    "                if value['type'] == 'power':\n",
    "                    consumption += value['values']\n",
    "\n",
    "    total_power.append([date, consumption])\n",
    "\n",
    "forecast = pd.DataFrame(total_power, columns=['datetime', 'consumption'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T16:49:04.101277208Z",
     "start_time": "2023-12-18T16:49:02.047883518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "forecast['datetime'] = pd.to_datetime(forecast['datetime'], format='%Y-%m-%d %H:%M:%S', dayfirst=True)\n",
    "forecast.set_index(\"datetime\", inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T16:49:04.153419824Z",
     "start_time": "2023-12-18T16:49:04.123722935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                     consumption\ndatetime                        \n2023-12-12 10:00:00  1700.000000\n2023-12-12 11:00:00  1701.777778\n2023-12-12 12:00:00  1701.077778\n2023-12-12 13:00:00  1706.933333\n2023-12-12 14:00:00  1708.000000\n2023-12-12 15:00:00  1708.000000\n2023-12-12 16:00:00  1708.000000\n2023-12-12 17:00:00  1708.000000\n2023-12-12 18:00:00  1709.997222\n2023-12-12 19:00:00  1710.000000\n2023-12-12 20:00:00  1694.055556\n2023-12-12 21:00:00  1690.000000\n2023-12-12 22:00:00  1690.000000\n2023-12-12 23:00:00  1690.000000\n2023-12-13 00:00:00  1690.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>consumption</th>\n    </tr>\n    <tr>\n      <th>datetime</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-12-12 10:00:00</th>\n      <td>1700.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 11:00:00</th>\n      <td>1701.777778</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 12:00:00</th>\n      <td>1701.077778</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 13:00:00</th>\n      <td>1706.933333</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 14:00:00</th>\n      <td>1708.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 15:00:00</th>\n      <td>1708.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 16:00:00</th>\n      <td>1708.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 17:00:00</th>\n      <td>1708.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 18:00:00</th>\n      <td>1709.997222</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 19:00:00</th>\n      <td>1710.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 20:00:00</th>\n      <td>1694.055556</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 21:00:00</th>\n      <td>1690.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 22:00:00</th>\n      <td>1690.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 23:00:00</th>\n      <td>1690.000000</td>\n    </tr>\n    <tr>\n      <th>2023-12-13 00:00:00</th>\n      <td>1690.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.resample('1H').mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T16:49:04.202621295Z",
     "start_time": "2023-12-18T16:49:04.130281650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(forecast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from database.BuildingRepository import BuildingRepository\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "building_repo = BuildingRepository()\n",
    "df = pd.DataFrame(building_repo.get_power_historic(datetime.now() - timedelta(days=30)))\n",
    "df = df.drop(\"_id\", axis=1)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "df = df.resample('15T').mean()\n",
    "df[\"datetime\"] = df.index\n",
    "\n",
    "df['totalpower'] = pd.to_numeric(df['totalpower'], errors='coerce')\n",
    "df['Month'] = df['datetime'].dt.month\n",
    "df['Day'] = df['datetime'].dt.day\n",
    "df['Hour'] = df['datetime'].dt.hour\n",
    "df['Weekday'] = df['datetime'].dt.weekday\n",
    "\n",
    "df.rename(columns={'totalpower': 'Consumption'}, inplace=True)\n",
    "df.drop(['datetime', 'totalgeneration'], axis=1, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "df['Consumption-1'] = df['Consumption'].shift(1)\n",
    "df.loc[df['Day'] != df['Day'].shift(1), 'Consumption-1'] = 0\n",
    "df['Consumption-2'] = df['Consumption'].shift(2)\n",
    "df.loc[df['Day'] != df['Day'].shift(2), 'Consumption-2'] = 0\n",
    "#df = df[['Month', 'Day', 'Hour', 'Consumption-1', 'Consumption-2', 'Consumption']]\n",
    "df = df[['Month', 'Day', 'Hour', 'Weekday', 'Consumption-1', 'Consumption-2', 'Consumption']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data preprocessing - Scaling using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "pred_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = pred_scaler.fit_transform(np.array(df['Consumption']).reshape(-1, 1))\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(df_scaled) * 0.8)\n",
    "test_size = len(df_scaled) - train_size\n",
    "train, test = df_scaled[0:train_size, :], df_scaled[train_size:len(df_scaled), :]\n",
    "print(\"Len train\", len(train), \"Len test\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming you have a scaler object named 'scaler'\n",
    "joblib.dump(scaler, 'training_1/scaler.pkl')\n",
    "joblib.dump(pred_scaler, 'training_1/pred_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Prepare data for LSTM (sequence-to-sequence)\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - 2):\n",
    "        X.append(data[i:i + time_steps, :-1])  # Exclude the last column (Consumption)\n",
    "        y.append(data[i + time_steps, -1])  # The last column (Consumption) is the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "timesteps = 1\n",
    "X_train, y_train = prepare_data(train, timesteps)\n",
    "X_test, y_test = prepare_data(test, timesteps)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape, \"timesteps\", timesteps)\n",
    "print(\"X_test shape\", X_test.shape, \"timesteps\", timesteps)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, X_train.shape[2]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, X_test.shape[2]))\n",
    "\n",
    "print(\"X_train shape\", X_train.shape, \"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape, \"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # LSTM model\n",
    "    model = Sequential()\n",
    "    print(timesteps, X_train.shape[2])\n",
    "    model.add(LSTM(units=50, input_shape=(timesteps, X_train.shape[2])))\n",
    "    model.add(Dense(units=1))  # Use the original number of features as the output units\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, mae, mse = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Trained model, mae: {:5.2f}%, mse: {:5.2f}%\".format(mae, mse))\n",
    "\n",
    "model.save('saved_model/consumption_forecast')\n",
    "\n",
    "y_train_inv = pred_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_inv = pred_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = pred_scaler.inverse_transform(y_train_pred)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred = pred_scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Display the original DataFrame and the predicted values after inverse scaling for train and test sets\n",
    "print(\"Original DataFrame:\")\n",
    "print(\"y_train_inv.shape\", y_train_inv.shape, \"y_train_pred.shape\", y_train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = create_model()\n",
    "\n",
    "loss, mae, mse = model_test.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Trained model, mae: {:5.2f}%, mse: {:5.2f}%\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "model_test.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, mae, mse = model_test.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Trained model, mae: {:5.2f}%, mse: {:5.2f}%\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/consumption_forecast')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n",
    "\n",
    "# Evaluate the restored model\n",
    "loss, mae, mse = new_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Trained model, mae: {:5.2f}%, mse: {:5.2f}%\".format(mae, mse))\n",
    "\n",
    "print(\"New Model Shape\", new_model.predict(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_train_inv, label='Actual (Train)', color='blue')\n",
    "plt.plot(y_train_pred, label='Pred (Train)', linestyle='dashed', color='red')\n",
    "\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Consumption')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(y_test_inv, label='Actual (Test)', color='green')\n",
    "plt.plot(y_test_pred, label='Pred (Test)', linestyle='dashed', color='orange')\n",
    "\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Consumption')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run modelwith saved weights\n",
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from database.BuildingRepository import BuildingRepository\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "building_repo = BuildingRepository()\n",
    "df_test = pd.DataFrame(building_repo.get_power_historic(datetime.now() - timedelta(hours=24)))\n",
    "df_test = df_test.drop(\"_id\", axis=1)\n",
    "\n",
    "df_test['datetime'] = pd.to_datetime(df_test['datetime'])\n",
    "# Calculate the datetime for 24 hours ago from the current time\n",
    "current_time = df_test['datetime'].max()\n",
    "twenty_four_hours_ago = current_time - timedelta(hours=24)\n",
    "\n",
    "# Filter the DataFrame to get only the rows for the last 24 hours\n",
    "last_24_hours_data = df_test[df_test['datetime'] >= twenty_four_hours_ago]\n",
    "\n",
    "last_24_hours_data['totalpower'] = pd.to_numeric(last_24_hours_data['totalpower'], errors='coerce')\n",
    "last_24_hours_data['Month'] = last_24_hours_data['datetime'].dt.month\n",
    "last_24_hours_data['Day'] = last_24_hours_data['datetime'].dt.day\n",
    "last_24_hours_data['Hour'] = last_24_hours_data['datetime'].dt.hour\n",
    "last_24_hours_data['Minute'] = last_24_hours_data['datetime'].dt.minute\n",
    "\n",
    "last_24_hours_data.rename(columns={'totalpower': 'Consumption'}, inplace=True)\n",
    "\n",
    "last_24_hours_data['datetime'] = pd.to_datetime(last_24_hours_data['datetime'], format='%Y-%m-%d %H:%M:%S',\n",
    "                                                dayfirst=True)\n",
    "last_24_hours_data.set_index(\"datetime\", inplace=True)\n",
    "last_24_hours_data = last_24_hours_data.resample('15T').mean()\n",
    "\n",
    "last_24_hours_data.drop(['totalgeneration'], axis=1, inplace=True)\n",
    "\n",
    "last_24_hours_data = last_24_hours_data.dropna()\n",
    "last_24_hours_data['Consumption-1'] = last_24_hours_data['Consumption'].shift(1)\n",
    "last_24_hours_data.loc[last_24_hours_data['Day'] != last_24_hours_data['Day'].shift(1), 'Consumption-1'] = 0\n",
    "last_24_hours_data['Consumption-2'] = last_24_hours_data['Consumption'].shift(2)\n",
    "last_24_hours_data.loc[last_24_hours_data['Day'] != last_24_hours_data['Day'].shift(2), 'Consumption-2'] = 0\n",
    "#last_24_hours_data = last_24_hours_data[['Month', 'Day', 'Hour', 'Consumption-1', 'Consumption-2', 'Consumption']]\n",
    "last_24_hours_data = last_24_hours_data[\n",
    "    ['Month', 'Day', 'Hour', 'Minute', 'Consumption-1', 'Consumption-2', 'Consumption']]\n",
    "last_24_hours_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the scaler\n",
    "scaler_test = joblib.load('training_1/scaler.pkl')\n",
    "pred_scaler_test = joblib.load('training_1/pred_scaler.pkl')\n",
    "\n",
    "df_scaled = scaler_test.fit_transform(last_24_hours_data)\n",
    "\n",
    "print(\"Len pred\", int(len(df_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 1\n",
    "\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - 2):\n",
    "        X.append(data[i:i + time_steps, :-1])  # Exclude the last column (Consumption)\n",
    "        y.append(data[i + time_steps, -1])  # The last column (Consumption) is the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "X_pred, y = prepare_data(df_scaled, timesteps)\n",
    "\n",
    "print(\"X_pred shape\", X_pred.shape, \"timesteps\", timesteps)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_pred = np.reshape(X_pred, (X_pred.shape[0], timesteps, X_pred.shape[2]))\n",
    "\n",
    "print(\"X_pred shape\", X_pred.shape, \"y_pred shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('saved_model/consumption_forecast')\n",
    "y_pred = model.predict(X_pred)\n",
    "y_pred = pred_scaler_test.inverse_transform(y_pred)\n",
    "y = pred_scaler_test.inverse_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y, label='Actual', color='blue')\n",
    "plt.plot(y_pred, label='Pred', linestyle='dashed', color='red')\n",
    "\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Consumption')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = scaler_test.inverse_transform(df_scaled[:-3])\n",
    "\n",
    "df = pd.DataFrame(last, columns=['Month', 'Day', 'Hour', 'Minute', 'Consumption-1', 'Consumption-2', 'Consumption'])\n",
    "df['Prediction'] = y_pred\n",
    "df['datetime'] = pd.to_datetime(df[['Month', 'Day', 'Hour', 'Minute']].assign(Year=2023))\n",
    "\n",
    "# Drop the separate columns if needed\n",
    "df.drop(['Month', 'Day', 'Hour', 'Minute'], axis=1, inplace=True)\n",
    "\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "df = df.resample('1H').mean()\n",
    "df[\"datetime\"] = df.index\n",
    "# Now, 'datetime' contains the combined datetime values\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiocps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
